{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('breast_cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32',\"id\"],axis=1,inplace=True)\n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
    "y = data.diagnosis.values\n",
    "x_data = data.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "x = (x_data -np.min(x_data))/(np.max(x_data)-np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (30, 483)\n",
      "x test:  (30, 86)\n",
      "y train:  (483,)\n",
      "y test:  (86,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # Update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692836\n",
      "Cost after iteration 10: 0.498576\n",
      "Cost after iteration 20: 0.404996\n",
      "Cost after iteration 30: 0.350059\n",
      "Cost after iteration 40: 0.313747\n",
      "Cost after iteration 50: 0.287767\n",
      "Cost after iteration 60: 0.268114\n",
      "Cost after iteration 70: 0.252627\n",
      "Cost after iteration 80: 0.240036\n",
      "Cost after iteration 90: 0.229543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 94.40993788819875 %\n",
      "test accuracy: 94.18604651162791 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9767441860465116 \n",
      "train accuracy: 0.968944099378882 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 150)\n",
    "print(\"test accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T)))\n",
    "print(\"train accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
